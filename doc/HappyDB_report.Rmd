---
title: "HappyDB_report"
author: "Shilin Li (sl4261)"
date: "9/11/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse) # general utility & workflow functions
library(tidytext) # tidy implimentation of NLP methods
library(topicmodels) # for LDA topic modelling 
library(tm) # general text mining functions, making document term matrixes
# library(SnowballC) # for stemming
```

## Read the data
```{r}
hm_data <- read_csv("~/Documents/GitHub/Fall2018-Proj1-lishilin63/data/cleaned_hm.csv")

demographic_data <- read_csv("~/Documents/GitHub/Fall2018-Proj1-lishilin63/data/demographic.csv")
```

This project mainly focuses on the exploration data analysis on the HappyDB dataset. The goal of the report is finding interesting pattern among people's happy moments. In the report, I will focus on the topic difference in people regarding gender, marital status, parenthood, and age groups. Similarities and differences in topics will be discussed.

## Preliminary cleanning hm_data text
I used a common stopword list in Kaggle (https://www.kaggle.com/rtatman/stopword-lists-for-19-languages#englishST.txt) to exclude these words appearing in the hm_data. Also, since our data are mostly related to happy moments, I also add words "happy", "happier", "happiest" etc. in the stopwords list.

The cleaning process also references the pre-processing document shared in class 
```{r text processing in tm}
# We clean the text by converting all the letters to the lower case, and removing punctuation, numbers, empty words and extra white space.
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
  tm_map(content_transformer(tolower))%>%
  tm_map(removePunctuation)%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, character(0))%>%
  tm_map(stripWhitespace)

# Stemming words and converting tm object to tidy object.
# Stemming reduces a word to its word *stem*. We stem the words here and then convert the "tm" object to a "tidy" object for much faster processing.
stemmed <- tm_map(corpus, stemDocument) %>%
  tidy() %>%
  select(text)

# Creating tidy format of the dictionary to be used for completing stems
# We also need a dictionary to look up the words corresponding to the stems.
dict <- tidy(corpus) %>%
  select(text) %>%
  unnest_tokens(dictionary, text)

# Removing stopwords that don't hold any significant information for our data set
# We remove stopwords provided by the "tidytext" package and also add custom stopwords in context of our data.
data("stop_words")

word <- c("happy","ago","yesterday","lot","today","months","month",
                 "happier","happiest","last","week","past","day","time","positive","experience","temple","favorite","extremely","tonight","function","movement")

stop_words <- stop_words %>%
  bind_rows(mutate(tibble(word), lexicon = "updated"))

# Combining stems and dictionary into the same tibble
# Here we combine the stems and the dictionary into the same "tidy" object.
completed <- stemmed %>%
  mutate(id = row_number()) %>%
  unnest_tokens(stems, text) %>%
  bind_cols(dict) %>%
  anti_join(stop_words, by = c("dictionary" = "word"))

# Stem completion
# Lastly, we complete the stems by picking the corresponding word with the highest frequency.
completed <- completed %>%
  group_by(stems) %>%
  count(dictionary) %>%
  mutate(word = dictionary[which.max(n)]) %>%
  ungroup() %>%
  select(stems, word) %>%
  distinct() %>%
  right_join(completed) %>%
  select(-stems)

# Pasting stem completed individual words into their respective happy moments
# We want our processed words to resemble the structure of the original happy moments. So we paste the words together to form happy moments.
completed <- completed %>%
  group_by(id) %>%
  summarise(text = str_c(word, collapse = " ")) %>%
  ungroup()

# Keeping a track of the happy moments with their own ID
hm_data <- hm_data %>%
  mutate(id = row_number()) %>%
  inner_join(completed)

head(hm_data)
```
The new hm_data has two new columns in which the "text" column is my analysis focus on. It has seperated word or phrase cleaned up with stopwords, and thus more relevant to the happy moments topics. 

I merged hm_data with the demographic_data. In this way, the whole file contains all the information about happy moments regarding age, gender, marital status and parenthood. The inner join process is by wid that each moment is paried by the recorders. Then, we could focus on our interest groups (gender, marital, parenthhood, age)
```{r}
hm_data <- hm_data %>%
  inner_join(demographic_data)

head(hm_data)
```

```{r}
ggplot(hm_data, aes(x=factor(1), fill=predicted_category)) + 
  geom_bar(width = 1) + 
  coord_polar("y")
```
Without subgrouping the hm_data, we could see generally a lot of people's happy moments come from achievements and affections. For example,
Achievements - I made a new recipe for peasant bread, and it came out spectacular!
             - I was shorting Gold and made $200 from the trade.
             - Managed to get the final trophy in a game I was playing.
Affections - I went on a successful date with someone I felt sympathy and connection with.
           - I was happy when my son got 90% marks in his examination
           - I went with grandchildren to butterfly display at Crohn Conservatory

Other happy moments also come from bonding, enjoy_the_moment and leisure which have relative smaller proportions. Nevertheless, the exercise and nature appears the lowest frequency among all the happy moments in the HappyDB.


## Supervised topic modeling with TF-IDF 
Reference: https://www.kaggle.com/rtatman/nlp-in-r-topic-modelling

In HappyDB, we have labeled data, so I used supervised topic modeling with TF-IDF (term frequency-inverse document frequency). The general idea behind how TF-IDF works is this:

- Words that are very common in a specific document are probably important to the topic of that document
- Words that are very common in all documents probably aren't important to the topics of any of them

So a term will recieve a high weight if it's common in a specific document and also uncommon across all documents.
```{r}
# function that takes in a dataframe and the name of the columns
# with the document texts and the topic labels. If plot is set to
# false it will return the tf-idf output rather than a plot.
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
    # name for the column we're going to unnest_tokens_ to
    # (you only need to worry about enquo stuff if you're
    # writing a function using using tidyverse packages)
    group_column <- enquo(group_column)
    text_column <- enquo(text_column)
    
    # get the count of each word in each review
    words <- text_df %>%
      unnest_tokens(word, !!text_column) %>%
      count(!!group_column, word) %>% 
      ungroup()

    # get the number of words per text
    total_words <- words %>% 
      group_by(!!group_column) %>% 
      summarize(total = sum(n))

    # combine the two dataframes we just made
    words <- left_join(words, total_words)
    
    # get the tf_idf & order the words by degree of relevence
    tf_idf <- words %>%
      bind_tf_idf(word, !!group_column, n) %>%
      select(-total) %>%
      arrange(desc(tf_idf)) %>%
      mutate(word = factor(word, levels = rev(unique(word))))
    
    if(plot == T){
        # convert "group" into a quote of a name
        # (this is due to funkiness with calling ggplot2
        # in functions)
        group_name <- quo_name(group_column)
        
        # plot the 10 most informative terms per topic
        tf_idf %>% 
          group_by(!!group_column) %>% 
          top_n(10) %>% 
          ungroup %>%
          ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +
          geom_col(show.legend = FALSE) +
          labs(x = NULL, y = "tf-idf") +
          facet_wrap(reformulate(group_name), scales = "free") +
          coord_flip()
    }else{
        # return the entire tf_idf dataframe
        return(tf_idf)
    }
}
```


## Informative descriptive words by gender
```{r}
top_terms_by_topic_tfidf(text_df = hm_data, # dataframe
                         text_column = text, # column with text
                         group_column = gender, # column with topic label
                         plot = T) # return a plot
```
From the extraction of the most frequently used terms by TF-IDF, We could directly observe that both males and females love pets (puppy) and they are both happy about childhood. While Females feel very happy about something in photos and males have fun moments with colleagues, with the key words extraction from the processed text, we could not tell an evident difference between males and females happy moments.

## Informative descriptive words by age group
Divide ages to groups
```{r,warning=FALSE}
library(data.table)

hm_data$age <- as.numeric(hm_data$age)

agebreaks <- c(0,20,30,40,50,60,500)
agelabels <- c("0-19","20-29","30-39","40-49","50-59","60+")

setDT(hm_data)[ , agegroups := cut(age, 
                                breaks = agebreaks, 
                                right = FALSE, 
                                labels = agelabels)]
```

```{r}
top_terms_by_topic_tfidf(text_df = hm_data, 
                         text_column = text, 
                         group_column = agegroups, 
                         plot = T) 
```
I used a common division criteria, 10 years old, in separating ages into 6 groups. The 0~19 group seems a majority of students in which their happy moments contain busboy and midterm. People greater than 20 years old share the common happy moments with the most outstanding "wife" word. Age groups in 50~59 and 60+ tend to mention granddaughter, grandchildren and grandkits a lot. This indeed makes sense that senior people's happy moments come a lot from their grandchildren.


```{r}
ggplot(data=hm_data, aes(x=predicted_category,fill = agegroups)) +
    geom_bar(stat="count")
```
In the bar chart, we could see that the happyDB survey collects a majority of people whose ages are between 20 to 40 years old. The happy moments are not evenly distributed among our age groups. Therefore, some of the top-words extracted (eg. 60+ age group) might not represent accurately the happy topics people in that age groups are talking.


## Informative descriptive words by marital
```{r}
top_terms_by_topic_tfidf(text_df = hm_data, 
                         text_column = text, 
                         group_column = marital, 
                         plot = T) 
```
The marital status contains five categories (divorced, married, separated, single and windowed). We could observe distinctive top words people are using. Divorced group has a lot of happy moments coming from finance, conversations and weekend. Married couples have many physchological happy moments with their spouse and memorable events. Separated group tends to have happy moments in shopping (Tommy), resturant and stock trading. Single group also focus on finance. Also, they mentioned a lot about semester. grandma, which may indicate a great proportion would be students. Widowed group does not have a focused topic in their top words and it might becasue of an relevant small sample size.

```{r}
ggplot(data=hm_data, aes(x=predicted_category,fill = marital)) +
    geom_bar(stat="count")
```
In the bar chart, we could see that generally people in each marital status group have similar proportion distribution in the predicted category. One interesting notice is that married couples have a larger proportion in affection than achievement. It makes sense that married people tend to have happy moments with their spouse.

## Informative descriptive words by parenthood
```{r}
top_terms_by_topic_tfidf(text_df = hm_data, 
                         text_column = text, 
                         group_column = parenthood, 
                         plot = T) 
```
The two distictive groups have great difference in their happy moments. People who do not have child talk in diverse topics such as fraternity, wifi, twitching and friend, while people with children talk a lot about grandchildren, hungary, daddy etc. It quite makes sense that people with children have a lot of happy moments with their children and people without have other things that make them happy.


```{r}
ggplot(data=hm_data, aes(x=predicted_category,fill = parenthood)) +
    geom_bar(stat="count")
```
From the bar chart we could observe that the achievement proportion of parenthood group is much less than that in affection group. And the nature proportion becomes larger than the exercise proportion. One possible explanation might be that people with children tend to have less time to go to the gym, but they are more likely to go to picnics, parks and hiking with their children.

## Conclusion
The EDA of the happyDB just scratch the surface of people's happy moments. A lot of interesting patterns are found in this dataset. Since the survey sample size is around 10000 in which some of the groups such as 0~20 age group, 60+ age group, divorced group, separated group and widowed group do not contain a large enough size, the inference in these small sample-size groups need to be further varified and researched. More detailed information and interesting facets are also encouraged to explore.

Lastly, I also find some moments are worth reading especially about "Boss" and "someone". I listed several of them below.

Boss:
- My current boss told me how much she is going to miss me and my work etiquette after I graduate and can no longer work for her at the end of this quarter.
- My boss give me bonus as Motorcycle its a very happiest moment for me.
- My boss randomly complimented me on a good job I've been doing lately.

Someone:
- On the train this morning, someone told me I had a nice smile.
- Someone who I admire in my school program told me that they thought I was very intelligent, warm, and funny.
- Someone at the store gave me fifty cents to cover the difference in money I didn't have from forgetting my wallet at home.